💻🧠📊📈🔍🤖📚📝⚙️🔬🔧🔗🖥️📉📡🔒🧑‍💻🌐💡🚀💻🧠📊📈🔍🤖📚📝⚙️🔬🔧🔗🖥️📉📡🔒🧑‍💻🌐💡🚀💻🧠📊📈🔍🤖📚📝⚙️🔬🔧🔗🖥️📉📡🔒🧑‍💻🌐💡🚀💻🧠📊📈🔍🤖📚📝⚙️🔬🔧🔗🖥️📉📡🔒🧑‍💻🌐💡🚀💻🧠📊📈🔍🤖📚📝⚙️🔬🔧🔗🖥️📉📡🔒🧑‍💻🌐💡🚀💻🧠📊📈🔍🤖📚📝⚙️🔬🔧🔗🖥️📉📡🔒🧑‍💻🌐💡🚀💻🧠📊📈🔍🤖📚📝⚙️🔬🔧🔗🖥️📉📡🔒🧑‍💻🌐💡🚀💻🧠📊📈🔍🤖📚📝⚙️🔬🔧🔗🖥️📉📡🔒🧑‍💻🌐💡🚀
Deep Learning Study

This repository contains a Jupyter Notebook focused on implementing a deep learning model for a classification problem. The project includes processing a dataset, building a neural network model, and evaluating its performance using various techniques.

Project Overview

The notebook demonstrates the following steps:

	1.	Data Preprocessing:
	•	Loading a dataset (date_fruit.xlsx).
	•	Normalizing the features using min-max scaling.
	•	Splitting the dataset into training and validation sets.
	2.	Model Creation:
	•	Building a neural network model using TensorFlow and Keras.
	•	Adding multiple fully connected layers with ReLU activation functions.
	•	Using Dropout layers to prevent overfitting.
	3.	Model Compilation:
	•	Optimizer: Adam.
	•	Loss Function: Sparse Categorical Crossentropy.
	•	Evaluation Metric: Accuracy.
	4.	Model Training:
	•	Training the model for 100 epochs.
	•	Evaluating the model’s performance on validation data.

Files

	•	Deep Learning study.ipynb: The main notebook containing all the code and explanations.
	•	date_fruit.xlsx: The dataset used for training and evaluation.

Installation and Usage

To run this project locally, follow these steps:

	1.	Clone the repository:
git clone https://github.com/your-username/deep-learning-study.git
	2.	Navigate to the project directory:
 cd deep-learning-study
	3.	Install the required Python libraries:
 pip install -r requirements.txt
 	4.	Open the notebook with Jupyter:
 jupyter notebook
Requirements

Ensure the following libraries are installed:

	•	TensorFlow
	•	Keras
	•	pandas
	•	scikit-learn
	•	matplotlib

Dataset

The dataset used is an Excel file (date_fruit.xlsx) containing various features. It is processed using Pandas, and label encoding is applied to categorical values.

Model Structure

	•	Input Layer: Input consisting of 34 features.
	•	Hidden Layers: Four fully connected layers with 4096 neurons each, using ReLU activation.
	•	Dropout Layers: Applied after each hidden layer to prevent overfitting.
	•	Output Layer: 7 neurons with Softmax activation for multi-class classification.

Results

The model is trained for 100 epochs with validation data, and accuracy and loss metrics are evaluated throughout the training process.


💻🧠📊📈🔍🤖📚📝⚙️🔬🔧🔗🖥️📉📡🔒🧑‍💻🌐💡🚀💻🧠📊📈🔍🤖📚📝⚙️🔬🔧🔗🖥️📉📡🔒🧑‍💻🌐💡🚀💻🧠📊📈🔍🤖📚📝⚙️🔬🔧🔗🖥️📉📡🔒🧑‍💻🌐💡🚀💻🧠📊📈🔍🤖📚📝⚙️🔬🔧🔗🖥️📉📡🔒🧑‍💻🌐💡🚀💻🧠📊📈🔍🤖📚📝⚙️🔬🔧🔗🖥️📉📡🔒🧑‍💻🌐💡🚀💻🧠📊📈🔍🤖📚📝⚙️🔬🔧🔗🖥️📉📡🔒🧑‍💻🌐💡🚀


Derin Öğrenme Çalışması

Bu depo, sınıflandırma problemi için derin öğrenme modelinin uygulanmasına odaklanan bir Jupyter Notebook içermektedir. Proje, bir veri kümesinin işlenmesini, bir sinir ağı modelinin oluşturulmasını ve çeşitli tekniklerle performansının değerlendirilmesini içermektedir.

Proje Özeti

Notebook’ta aşağıdaki adımlar gösterilmektedir:

	1.	Veri Ön İşleme:
	•	Bir veri kümesinin (date_fruit.xlsx) yüklenmesi.
	•	Özelliklerin min-max ölçeklendirilmesi ile normalizasyon işlemi.
	•	Veri kümesinin eğitim ve doğrulama setlerine bölünmesi.
	2.	Model Oluşturma:
	•	TensorFlow ve Keras kullanarak bir sinir ağı modelinin oluşturulması.
	•	ReLU aktivasyon fonksiyonuna sahip birden fazla tam bağlı katmanın eklenmesi.
	•	Aşırı öğrenmeyi önlemek için Dropout katmanlarının kullanılması.
	3.	Model Derleme:
	•	Optimizasyon: Adam.
	•	Kayıp Fonksiyonu: Sparse Categorical Crossentropy.
	•	Başarı Ölçütü: Doğruluk (Accuracy).
	4.	Model Eğitimi:
	•	Modelin 100 epoch boyunca eğitilmesi.
	•	Doğrulama verileri üzerinden modelin performansının değerlendirilmesi.

Dosyalar

	•	Deep Learning study.ipynb: Tüm kodları ve açıklamaları içeren ana notebook.
	•	date_fruit.xlsx: Modelin eğitim ve değerlendirmesinde kullanılan veri seti.

Kurulum ve Kullanım

Bu projeyi yerel olarak çalıştırmak için şu adımları izleyin:

	1.	Depoyu klonlayın:
 git clone https://github.com/kullanici-adi/derin-ogrenme-calismasi.git
 	2.	Proje dizinine gidin:
cd derin-ogrenme-calismasi
	3.	Gerekli Python kütüphanelerini yükleyin:
 pip install -r requirements.txt
	4.	Notebook’u Jupyter ile açın:
jupyter notebook

Gereksinimler

Aşağıdaki kütüphanelerin kurulu olduğundan emin olun:

	•	TensorFlow
	•	Keras
	•	pandas
	•	scikit-learn
	•	matplotlib

Veri Kümesi

Kullanılan veri seti, bir Excel dosyasıdır (date_fruit.xlsx) ve birçok özelliği içermektedir. Bu veri seti Pandas kullanılarak işlenir ve kategorik değerler için etiketleme yapılır.

Model Yapısı

	•	Giriş Katmanı: 34 özellikten oluşan giriş.
	•	Gizli Katmanlar: 4096 nöronlu dört tam bağlı katman, ReLU aktivasyonu ile.
	•	Dropout Katmanları: Aşırı öğrenmeyi önlemek için her gizli katmandan sonra kullanılır.
	•	Çıkış Katmanı: 7 nöronlu, çok sınıflı sınıflandırma için Softmax aktivasyonu ile.

Sonuçlar

Model, 100 epoch boyunca doğrulama verisi ile eğitilir ve eğitim süresince doğruluk ve kayıp değerleri değerlendirilir.


















 
